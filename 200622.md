Day 23.

## 목차
 
## 10. 가상화

> ### 10.1 가상화 개요
> ### 10.2 oVirt 개요
> ### 10.3 oVirt 데이터 센터 및 클러스터
> ### 10.4 호스트 추가 및 제거
> ### 10.0 기술지원 FAQ


------------
 
 
## 10 가상화


가상화(Virtualization)는 컴퓨터에서 컴퓨터 리소스의 추상화를 일컫는 광범위한 용어이다. "물리적인 컴퓨터 리소스의 특징을 다른 시스템, 응용 프로그램, 최종 사용자들이 리소스와 상호 작용하는 방식으로부터 감추는 기술"로 정의할 수 있다.


------------

 
### 10.1 가상화 개요


**가상화 목적**
* Isolation(격리성) : 격리성을 보장하여 보안, 비용 등 최대한의 효율을 이끌어 낸다.


**하이퍼 바이저 개요**
* H/W를 소프트웨어적으로 파티셔닝하여 가상머신에게 제공
* 주요 기능은 시스템 자원 관리, 모니터링, 독립성 유지,주변 장치 제공


<br/>


**서버/시스템 가상화 종류**
* Baremetal/Native Virtualization(**Type 1**)
> * hardware - hypervisor - guestOS(kernel - App) 
> * hypervisor가 하드웨어를 격리 시킴(나눔)
> * hypervisor 제품 : VMware ESXi(ESX), Citrix Xen Server(Xen Open Source), RedHat RHV(KVM), Microsoft Htper-V
> * Virtualization Management 제품 : VMware vCenter, Citrix Xen Center, RedHat RHV(oVirt), MS SCVMM


   <img src="https://user-images.githubusercontent.com/56064985/85347298-1f38d800-b533-11ea-9e21-04973cc41820.png" width="40%"></img>


* Hosted Virtualization(**Type 2**)
> * hardware - hostOS(kernel - app or hypervisor) -guestOS(kernel - App) 
> * 제품 : VMWorkstation, Oracle VirtualBox


   <img src="https://user-images.githubusercontent.com/56064985/85347301-1fd16e80-b533-11ea-884e-64492b31d1ad.png" width="40%"></img>


* Full Virtualization(디스크 전가상화)
> * 가상머신이 제공받은 하드웨어가 전부 가상의 하드웨어
> * 전가상화로 만들어진 가상머신은 자신이 가상머신인지 알지 못함
> * 물리적인 하드웨어에 접근할 때 하이퍼 바이저에 의해 제어됨
> * 에뮬레이트 작업을 거치기 때문에 성능이 떨어짐
> * 대부분의 운영체제를 쉽게 설치 가능
> * Binary Translation : hypervisor와 hardware가 서로 알아들을 수 있는 언어로 변환해줌(SW였지만 지금은 HW가 지원해줌-VT)


* Para Virtualization(디스크 반가상화)
> * 운영체제의 커널 소스를 수정한 가상화
> * 전가상화보다 오버헤드가 적음
> * 운영체제의 커널 소스를 수정해야 하기 때문에 오픈소르 운영체제로 한정
> * hyper Call : APP이 hardware로 바로 명령을 내릴 수 있음


---


### 10.2 oVirt 개요

**oVirt 목적**
* Host와 Guest 시스템을 중앙에서 관리하는 가상화 플랫폼(PaaS)
* 기능 : Hardware 노드 관리, storage 및 네트워크 자원 관리, 가상머신 배포 및 관리 기능


<br/>


**KVM**
* Thin Hypervisor Host
> * Baremetal형 하이퍼바이저
> * 어떤 서비스도 제공이 안됨(ssh 제외)

* Thick Hypervisor Host
> * Hosted형 하이퍼바이저
> * 운영체제에 하이퍼바이저 소프트웨어를 설치하여 사용
> * Guest 시스템을 설치하기가 쉬움


<br/>


**oVirt 설치**

* oVirt 구성도


<img src="https://user-images.githubusercontent.com/56064985/85265996-236ee200-b4ae-11ea-8ab6-1e792cabee25.png" width="90%"></img>



[ovirt thin 클라이언트]

* ovirt thin 클라이언트 서버 설치 파일 사전 작업(Ubuntu : 사용자 PC)
```
# cd /var/lib/libvirt/images     //  패키지 설치 디렉토리로 이동
# qemu-img create hyper2.raw 55G   // 서버 파일 미리 만들기
# qemu-img convert -O qcow2 hyper1.raw hyper1.qcow2

```


* ovirt thin 클라이언트 서버 qcow2 설치


<img src="https://user-images.githubusercontent.com/56064985/85362434-633ed380-b559-11ea-9708-0c70119dd377.png" width="60%"></img>

<img src="https://user-images.githubusercontent.com/56064985/85362440-65089700-b559-11ea-8f32-d6f0627d6f0c.png" width="60%"></img>

<img src="https://user-images.githubusercontent.com/56064985/85362444-68038780-b559-11ea-8a89-ca43909da6ec.png" width="60%"></img>

<img src="https://user-images.githubusercontent.com/56064985/85362449-6a65e180-b559-11ea-9fc5-8501d027c735.png" width="60%"></img>


* ovirt thin 클라이언트 서버 사양 설정


<img src="https://user-images.githubusercontent.com/56064985/85362456-6e91ff00-b559-11ea-82e8-18fc69422213.png" width="60%"></img>

<img src="https://user-images.githubusercontent.com/56064985/85362460-6fc32c00-b559-11ea-8bed-1db49b795668.png" width="60%"></img>

<img src="https://user-images.githubusercontent.com/56064985/85362464-72be1c80-b559-11ea-99d7-dff3dc4843d0.png" width="60%"></img>

<img src="https://user-images.githubusercontent.com/56064985/85362465-7487e000-b559-11ea-86ca-5c2b5c6ece9d.png" width="60%"></img>

<img src="https://user-images.githubusercontent.com/56064985/85362470-7651a380-b559-11ea-9e19-bbe4236f457b.png" width="60%"></img>


* ovirt 패키지 최신화 진행
```
# yum update 

```


* vi /etc/hosts 추가
```
# vi /etc/hosts

192.168.122.10  ovirt.abc.local
192.168.122.21  hyper1.abc.local
192.168.122.22  hyper2.abc.local

:wq!

```


* ssh public key 설정
```
# mkdir /root/.ssh
# chmod 700 /root/.ssh
# vi /root/.ssh/authorized.keys

sh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCnY53ST2RxdulhwysvLWxjiCRX1XbqvCiidGT5LjGgXIvvEfG8zqhiozEVW4yNVApufjsLjNOE0vMZ204Gi5PEm67ZoDDB5qsOvs93eqaR0CS0qdNuo0KzbLtFbPzGEPw9+vRsiRyk4qIgDYpYwCRkV1vn3NfAe0c+mUvxCgvyp5kfFWbSyvt7gN5tbwbX+PpSJ0HIVpfrOO6Y4R8TfZwo6pacwgLKEH4sId8L/cqfR29nIm93WJRoqGjCilD6GLldHzySjjeL+rdTsZyJzz0BtLNGSmxUxhnm3jyNs836d/bPTS0L9xx7n3oGSE3ISTh/yJBmsO5x0I+Lw4U+jfdD ovirt-engine

:wq!

```


[ovirt thick 클라이언트]
* ovirt thick 서버 패키지 설치
```
# yum update  // 시스템 최신화(커널)
# yum install http://resources.ovirt.org/pub/yum-repo/ovirt-release43.rpm   // ovirt 패키지 설치
# yum install qemu-kvm libvirt virt-install bridge-utils vdsm-client   // 자동 추가가 안될 경우 진행
# yum update  // ovirt 패키지 업데이트 확인
# reboot
```

* vi /etc/hosts 추가
```
# vi /etc/hosts

192.168.122.10  ovirt.abc.local
192.168.122.21  hyper1.abc.local
192.168.122.22  hyper2.abc.local

:wq!

```

* ssh public key 설정
```
# mkdir /root/.ssh
# chmod 700 /root/.ssh
# vi /root/.ssh/authorized.keys

sh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCnY53ST2RxdulhwysvLWxjiCRX1XbqvCiidGT5LjGgXIvvEfG8zqhiozEVW4yNVApufjsLjNOE0vMZ204Gi5PEm67ZoDDB5qsOvs93eqaR0CS0qdNuo0KzbLtFbPzGEPw9+vRsiRyk4qIgDYpYwCRkV1vn3NfAe0c+mUvxCgvyp5kfFWbSyvt7gN5tbwbX+PpSJ0HIVpfrOO6Y4R8TfZwo6pacwgLKEH4sId8L/cqfR29nIm93WJRoqGjCilD6GLldHzySjjeL+rdTsZyJzz0BtLNGSmxUxhnm3jyNs836d/bPTS0L9xx7n3oGSE3ISTh/yJBmsO5x0I+Lw4U+jfdD ovirt-engine

:wq!

```


* 관리 페이지에서 자동 설치가 안되면 다음을 진행(보안에 취약해지나 테스트 환경이기 때문에 진행)
```
# systemctl stop firewalld
# setenforce 0
```


[ovirt 서버]••••
* ovirt 서버 패키지 설치
```
# yum update  // 시스템 최신화(커널)
# yum install http://resources.ovirt.org/pub/yum-repo/ovirt-release43.rpm   // ovirt 패키지 설치
# yum update  // ovirt 패키지 업데이트 확인
# yum install ovirt-engine
# reboot
```


* manage 구성
```
# engine-setup

전부 기본 값으로 설치 진행
[WARNING] Less than 16384MB of memory is available
         
          --== CONFIGURATION PREVIEW ==--
         
          Application mode                        : both
          Default SAN wipe after delete           : False
          Firewall manager                        : firewalld
          Update Firewall                         : True
          Host FQDN                               : ovirt.abc.local
          Set up Cinderlib integration            : False
          Configure local Engine database         : True
          Set application as default page         : True
          Configure Apache SSL                    : True
          Engine database secured connection      : False
          Engine database user name               : engine
          Engine database name                    : engine
          Engine database host                    : localhost
          Engine database port                    : 5432
          Engine database host name validation    : False
          Engine installation                     : True
          PKI organization                        : abc.local
          Set up ovirt-provider-ovn               : True
          Configure WebSocket Proxy               : True
          DWH installation                        : True
          DWH database host                       : localhost
          DWH database port                       : 5432
          Configure local DWH database            : True
          Configure Image I/O Proxy               : True
          Configure VMConsole Proxy               : True


[ INFO  ] Restarting httpd
          Please use the user 'admin@internal' and password specified in order to login
          Web access is enabled at:
              http://ovirt.abc.local:80/ovirt-engine   // 접근하기 위한 URL
              https://ovirt.abc.local:443/ovirt-engine   // 접근하기 위한 URL
          Internal CA 74:F0:21:62:CF:18:E6:54:B4:48:37:7C:81:C8:4E:7E:3A:90:CC:3B
          SSH fingerprint: SHA256:Ihq6aQhN2gfUymsd84CuAcjmUnh9WngAK1JcuuZgqr0   // SSH 접근을 위해 기억하기
[WARNING] Less than 16384MB of memory is available
         
          --== END OF SUMMARY ==--
         
[ INFO  ] Stage: Clean up
          Log file is located at /var/log/ovirt-engine/setup/ovirt-engine-setup-20200622152524-t8r1th.log
[ INFO  ] Generating answer file '/var/lib/ovirt-engine/setup/answers/20200622154945-setup.conf'
[ INFO  ] Stage: Pre-termination
[ INFO  ] Stage: Termination
[ INFO  ] Execution of setup completed successfully

```
* vi /etc/hosts 추가
```
# vi /etc/hosts

192.168.122.10  ovirt.abc.local
192.168.122.21  hyper1.abc.local
192.168.122.22  hyper2.abc.local

:wq!

```


* ubuntu(사용자 PC) hosts 파일 추가 
```
# vi /etc/hosts
192.168.122.10 ovirt.abc.local
```

* 관리 페이지 접근


<img src="https://user-images.githubusercontent.com/56064985/85257783-5b235d00-b4a1-11ea-80e8-08ed1569a8f5.png" width="90%"></img>


<img src="https://user-images.githubusercontent.com/56064985/85257795-5eb6e400-b4a1-11ea-9c72-47862302f74a.png" width="90%"></img>


<img src="https://user-images.githubusercontent.com/56064985/85257804-6080a780-b4a1-11ea-82d0-d66fd6e23c14.png" width="90%"></img>


* Host 추가 및 관리


<img src="https://user-images.githubusercontent.com/56064985/85263051-91fd7100-b4a9-11ea-9616-fa719bd0af74.png" width="90%"></img>


<img src="https://user-images.githubusercontent.com/56064985/85263056-93c73480-b4a9-11ea-8239-297395934ec7.png" width="90%"></img>


<img src="https://user-images.githubusercontent.com/56064985/85265590-76946500-b4ad-11ea-82fb-3b4ae1f5707d.png" width="90%"></img>


---


### 10.3 ovirt 데이터 센터 및 클러스터 생성

#### 데이터 센터


* 개요
> * 모든 물리적 및 논리적 자원을 포함한 최상위 조직 객체
> * 단일 데이터 센터는 독립적인 가상화 환경


<img src="https://user-images.githubusercontent.com/56064985/85501697-d7907a00-b620-11ea-9d58-6ec1dfc66923.png" width="75%"></img>



* Storage 컨테이너
> * Storage 도메인에 대한 연결 정보
> * storage 유형 및 storage 도메인 정보가 저장 
> * 해당 데이터 센터의 모든 클러스터에서 사용 가능
> *  모든 호스트 클러스터는 같은 storage 도메인에 액세스 가능


* 네트워크 컨테이너
> * 데이터 센터의 논리 네트워크 정보가 저장
> * 네트워크 주소, VLAN 태그 및 STP 지원 등의 상세 정보도 포함
> * 트래픽 분리를 위해 다수의 논리 네트워크 구성 가능




#### 클러스터 파일 시스템 추가

* 파일 시스템 추가(ovirt 서버 내에 추가 진행)
```
# fdisk /dev/vdb

Command (m for help): n
Partition type:
   p   primary (0 primary, 0 extended, 4 free)
   e   extended
Select (default p): p
Partition number (1-4, default 1): 
First sector (2048-104857599, default 2048): 
Using default value 2048
Last sector, +sectors or +size{K,M,G} (2048-104857599, default 104857599): 
Using default value 104857599
Partition 1 of type Linux and of size 50 GiB is set

Command (m for help): w


# fdisk /dev/vdc
Welcome to fdisk (util-linux 2.23.2).

Changes will remain in memory only, until you decide to write them.
Be careful before using the write command.

Device does not contain a recognized partition table
Building a new DOS disklabel with disk identifier 0xaa0f03cb.

Command (m for help): n
Partition type:
   p   primary (0 primary, 0 extended, 4 free)
   e   extended
Select (default p): p
Partition number (1-4, default 1): 
First sector (2048-104857599, default 2048): 
Using default value 2048
Last sector, +sectors or +size{K,M,G} (2048-104857599, default 104857599): 
Using default value 104857599
Partition 1 of type Linux and of size 50 GiB is set

Command (m for help): w
The partition table has been altered!

# lsblk
NAME            MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sr0              11:0    1  4.5G  0 rom  
vda             252:0    0   20G  0 disk 
├─vda1          252:1    0    1G  0 part /boot
└─vda2          252:2    0   19G  0 part 
  ├─centos-root 253:0    0   17G  0 lvm  /
  └─centos-swap 253:1    0    2G  0 lvm  [SWAP]
vdb             252:16   0   50G  0 disk 
└─vdb1          252:17   0   50G  0 part 
vdc             252:32   0   50G  0 disk 
└─vdc1          252:33   0   50G  0 part 

# mkfs.ext4 /dev/vdb1
# mkfs.ext4 /dev/vdc1
# lsblk

```

* exports 설정 및 마운트
```
# mkdir -p /export/data
# mkdir -p /export/iso
# chown -R vdsm:kvm /export/
# chmod -R g+s /export/
# vi /etc/exports

/export/iso     192.168.122.0/24(rw,sync,no_root_squash)
/export/data    192.168.122.0/24(rw,sync,no_root_squash)
~                                                             

:wq!

# exportfs -arv
exporting 192.168.122.0/24:/export/data
exporting 192.168.122.0/24:/export/iso

# vi /etc/fstab

/dev/vdb1       /export/data    ext4    defaults        0 0
/dev/vdc1       /export/iso     ext4    defaults        0 0

:wq!

# mount -a
```

* 방화벽 및 서비스 설정
```
# systemctl start nfs-server
# systemctl enable nfs-server
Created symlink from /etc/systemd/system/multi-user.target.wants/nfs-server.service to /usr/lib/systemd/system/nfs-server.service.
# firewall-cmd --permanent --add-service=nfs
success
# firewall-cmd --permanent --add-service=rpc-bind
success
# firewall-cmd --permanent --add-service=mountd
success
# firewall-cmd --reload
success

```

* 관리자 페이지를 통한 storage 추가


<img src="https://user-images.githubusercontent.com/56064985/85383916-8aa69800-b57b-11ea-93d8-7c4e700e87ac.png" width="90%"></img>


<img src="https://user-images.githubusercontent.com/56064985/85384050-b45fbf00-b57b-11ea-9213-c7035a5bfa0c.png" width="90%"></img>


<img src="https://user-images.githubusercontent.com/56064985/85384057-b6c21900-b57b-11ea-93eb-d18c539594f8.png" width="90%"></img>


---


### 10.4 호스트 추가 및 제거

#### 호스트 추가 

* 호스트 패키지([storage] 서버 내의 'iso' 디렉토리에 호스트 설치 iso를 다운로드)
```
# yum install wget
# cd /export/iso
# wget http://192.168.0.252/ISOs/CentOS-7-x86_64-Minimal-2003.iso   // 교육장 저장소에서 iso 파일 가져오기
# engine-iso-uploader list   // iso 연결 상태확인
Please provide the REST API password for the admin@internal oVirt Engine user (CTRL+D to abort): 
ISO Storage Domain Name   | ISO Domain Status
nfs-iso                   | ok
# engine-iso-uploader -i nfs-iso upload CentOS-7-x86_64-Minimal-2003.iso   // iso 저장소에 iso 파일 업로드
Please provide the REST API password for the admin@internal oVirt Engine user (CTRL+D to abort): 
Uploading, please wait...
INFO: Start uploading CentOS-7-x86_64-Minimal-2003.iso 
Uploading: [########################################] 100%
INFO: CentOS-7-x86_64-Minimal-2003.iso uploaded successfully

```


* 호스트 설치(호스트 설치에 앞서, [storage] 의 'nfs-data' 와 'nfs-iso'가 잘 붙어 있는지 확인)


<img src="https://user-images.githubusercontent.com/56064985/85489728-64c8d400-b60b-11ea-99a4-ece40ff40809.png" width="90%"></img>

<img src="https://user-images.githubusercontent.com/56064985/85489734-66929780-b60b-11ea-9c1b-cc03e43c09d2.png" width="90%"></img>



* 호스트 부팅 장치 시스템 설정(한번의 실행 옵션으로 최초 실행시에만 CD-ROM을 연결하여 iso 파일 설치 진행)


<img src="https://user-images.githubusercontent.com/56064985/85490205-50d1a200-b60c-11ea-8310-2ea82da011e6.png" width="90%"></img>


<img src="https://user-images.githubusercontent.com/56064985/85490211-5202cf00-b60c-11ea-857d-e5d5b9fc0a02.png" width="90%"></img>



* 호스트 연결하기
```
#



```


---


### 10.0 기술지원 FAQ

* FAQ 0. 파일 시스템 추가시 용량이 부족한 경우
```
# qemu-img create nfs-iso.raw 50G
# qemu-img create nfs-data.raw 50G
# qemu-img convert -O qcow2 nfs-iso.raw nfs-iso.qcow2
# qemu-img convert -O qcow2 nfs-data.raw nfs-data.qcow2
```


* FAQ 1. storage 추가 작업시, 이전에 삭제했던 storage 파일이 남아있어서 진행이 안될 경우
```
# rm -rf /export/data/*
# rm -rf /export/iso/*
```


* FAQ 2. storage 추가 작업시, ovirt.abc.local 의 도메인을 인식하지 못하는 경우
> * 도메인 대신 ip주소를 기입
```
192.168.122.10:/export/data
```


* FAQ 3. 부팅 시, storage가 비활성화되어 연결이 되지 않는 경우
> * storage nfs 마운트된 파일의 권한 문제가 발생한 경우가 있음
> * storage 서버 내의 마운트 디렉토리의 권한을 확인함
```
# cd /export/
# ls -al
drwxr-xr-x.  4 root root    29 Jun 23 16:32 .
dr-xr-xr-x. 18 root root  238 Jun 23 16:32 ..
drwxr-xr-x.  5 root root  4096 Jun 24 11:01 data
drwxr-xr-x.  4 root root  4096 Jun 24 10:59 iso

# chmod -R g+s /export/
# chown -R 36:36 /export/
# ls -al
drwxr-sr-x.  4 vdsm kvm    29 Jun 23 16:32 .
dr-xr-xr-x. 18 root root  238 Jun 23 16:32 ..
drwxr-sr-x.  5 vdsm kvm  4096 Jun 24 11:01 data
drwxr-sr-x.  4 vdsm kvm  4096 Jun 24 10:59 iso

```

* FAQ 4. storage 목록을 지우려면 해당 storage를 관리하는 호스트를 management 상태로 변경해야 함
> * ovirt manage에서 [compute] - [host] 로 이동하여 해당 host를 management 상태로 변경
> * 유지보수 모드는 서버를 끄는 것이 아니라 해당 서버를 사용하지 못하게 하는 상태(자신에게 있는 서버들을 다른 호스트로 자동으로 마이그레이션 진행)


<img src="https://user-images.githubusercontent.com/56064985/85489294-c177bf00-b60a-11ea-8626-a054260aeb13.png" width="90%"></img>




#### 추가 공부 내용

```
Java Web Application
Web server
Web Application Server(WAS)
 Opensource : JBoss --> WildFly
 Eneterprise : JBoss ES
SAN(Storage Area Network)

FC-SAN : Fiber Chanel
 HBA(Host Bus Adapter) : FC
 FC Protocol
 SAN Switch
 
IP-SAN(iSCSI, FCoE...)
 Ethernet NIC
 TCP/IP Protocol
 Ethernet Switch

PSTN : 서킷 스위칭(회로 교환 방식)
VoIP(Voice over IP)
VOLTE(Voice over LTE) : 패킷 스위칭 방식

도커 강의 :https://www.slideshare.net/pyrasis/docker-fordummies-44424016




```


---
